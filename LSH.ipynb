{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "LSH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sapienhwaker/Locality-Sensitive-Hashing/blob/main/LSH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7XHGFQJ6ikL"
      },
      "source": [
        "#Prasad Hajare A20232707"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSmdp1Chn1ix"
      },
      "source": [
        "## Prasad Hajare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_EFdpdu6ikT"
      },
      "source": [
        "Locality Sensitive Hashing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHT646P50zID"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaq9X2ys6ikV"
      },
      "source": [
        "#Importing relevent packages\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "from shutil import copyfile\n",
        "\n",
        "import sys\n",
        "import re\n",
        "import collections\n",
        "#from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3f9yYL86ika"
      },
      "source": [
        "## Execute the follwing two cells to generate your data sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9AmQ_-Q6ikb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "978310cb-f0b9-4697-98cb-b2bbc2295158"
      },
      "source": [
        "MY_ID = '819'\n",
        "#My_ID = '707'\n",
        "# MY_ID should be string\n",
        "# Example MY_ID='819'\n",
        "\n",
        "task_dict = {0:'taska',1:'taskb',2:'taskc',3:'taskd',4:'taske'}\n",
        "\n",
        "\n",
        "try:\n",
        "    n_1 = int(MY_ID[-1]) % 5\n",
        "    n_2 = int(MY_ID[-2]) % 5\n",
        "    n_3 = int(MY_ID[-3]) % 5\n",
        "    \n",
        "    while n_1 == n_2 or n_1 == n_3:\n",
        "        n_1 = (n_1 + 1) % 5\n",
        "    \n",
        "    while n_1 == n_2 or n_2 == n_3:\n",
        "        n_2 = (n_2 + 1) % 5\n",
        "        \n",
        "except Exception as e:\n",
        "    print('Please enter a valid ID...')\n",
        "\n",
        "id_dict = {0:n_1,1:n_2,2:n_3}\n",
        "print(id_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 4, 1: 1, 2: 3}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMxxHY8v3qxG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9107f59d-ddab-48f2-c624-b47bfa0ffdcc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5tZ41Fd6ikf"
      },
      "source": [
        "data_path = '/content/drive/My Drive/BIGDATA Fall2020/Project_2/corpus-20090418' \n",
        "# Edit this path if the data directory is not in the current directory\n",
        "\n",
        "try:\n",
        "    os.makedirs('Data_Sample')\n",
        "    os.makedirs('Original_Sample')\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "for i in range(3):\n",
        "    task = task_dict[id_dict[i]]\n",
        "    \n",
        "    for file in os.listdir(data_path):\n",
        "        if task in file:\n",
        "            if 'orig' in file:\n",
        "                copyfile(data_path + '/' + file, 'Original_Sample/' + file)\n",
        "            else:\n",
        "                copyfile(data_path + '/' + file, 'Data_Sample/' + file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFz3a2d96ikk"
      },
      "source": [
        "Your dataset for this project will be in <b>Data_Sample</b>\n",
        "\n",
        "\n",
        "Your query choices will be in <b>Original_Sample</b> directory\n",
        "\n",
        "\n",
        "You have to use any one original Wikipedia article from <b>Original_Sample</b> for <b>Fact Check</b> steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q32elJTv0jj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU7tiK9i6ikp"
      },
      "source": [
        "### STEP - 1: Shingling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_rKB9doXBKU"
      },
      "source": [
        "## function to get shingles from the sample documents\n",
        "def get_sample_shingles(k, fileIndex):\n",
        "  fileNumber = fileIndex\n",
        "  data_sample_path = '/content/Data_Sample'\n",
        "  for file in os.listdir(data_sample_path):\n",
        "    file_address = data_sample_path + \"/\" + file\n",
        "    try:\n",
        "      f = open(file_address, 'rb')\n",
        "      file_data = f.read().lower()\n",
        "      templi = re.split(rb'\\W+', file_data)\n",
        "      #print(\"Processed file:\", fileNumber)\n",
        "      index = 0\n",
        "      temp_set = set()\n",
        "      while index < len(templi)-k:\n",
        "        count = 0\n",
        "        s = b\" \"\n",
        "        space = b\" \"\n",
        "        while count < k:\n",
        "          s = b\"\".join([s, templi[index+count], space])\n",
        "          count += 1\n",
        "  \n",
        "        index += 1\n",
        "        temp_set.add(s.strip().lower())\n",
        "        shingles_set.add(s.strip().lower())\n",
        "      dictionary[fileNumber] = temp_set\n",
        "      name_index[fileNumber] = file\n",
        "      fileNumber += 1\n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVYu0aDlLiJj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A_2oTgFyKkp"
      },
      "source": [
        "## Function to get shingles from original documents\n",
        "def get_original_shingles(k, fileIndex):\n",
        "  fileNumber = fileIndex\n",
        "  original_sample_path = '/content/Original_Sample'\n",
        "  for file in os.listdir(original_sample_path):\n",
        "    file_address = original_sample_path + \"/\" + file\n",
        "    try:\n",
        "      f = open(file_address, 'rb')\n",
        "      file_data = f.read().lower()\n",
        "      templi = re.split(rb'\\W+', file_data)\n",
        "      #print(\"Processed file:\", fileNumber)\n",
        "      \n",
        "      index = 0\n",
        "      temp_set = set()\n",
        "      while index < len(templi)-k:\n",
        "        count = 0\n",
        "        s = b\" \"\n",
        "        space = b\" \"\n",
        "        while count < k:\n",
        "          s = b\"\".join([s, templi[index+count], space])\n",
        "          count += 1\n",
        "  \n",
        "        index += 1\n",
        "        temp_set.add(s.strip())\n",
        "        shingles_set.add(s.strip())\n",
        "      dictionary[fileNumber] = temp_set\n",
        "      name_index[fileNumber] = file\n",
        "      fileNumber += 1\n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOKJxoQCMC3j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4a63da29-e564-4cd0-fba2-3f35049e21bf"
      },
      "source": [
        "## Getting shingles for k =3, 4, 5\n",
        "\n",
        "for k in range(3,6):\n",
        "  dictionary = dict()\n",
        "  shingles_set = set()\n",
        "  name_index = dict()\n",
        "  get_sample_shingles(k, 0)\n",
        "  get_original_shingles(k, len(dictionary))\n",
        "  print(\"k = \" + str(k) + \" : \" + str(len(shingles_set)))\n",
        "  #print(dictionary[46])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k = 3 : 7827\n",
            "k = 4 : 8721\n",
            "k = 5 : 9132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRFDPJx76iky"
      },
      "source": [
        "Report results (number of unique k-shingles) for k={3,4,5} below:\n",
        "1. k=3: 7827\n",
        "2. k=4: 8721\n",
        "3. k=5: 9132"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhdK7EbGZukr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h52iG-SqKjFD"
      },
      "source": [
        "## Indexing of shingles for k = 5\n",
        "shingles_list = list(shingles_set)  #the index number in the list will be the index for each specific shingle\n",
        "#print(shingles_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fQR--Oa6ik5"
      },
      "source": [
        "### STEP - 2: Min-Hashing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2NjFas_uXio"
      },
      "source": [
        "# ***************************************************NEW***********************************************************\n",
        "# Generate Hash functions - \n",
        "    # We use (ax + b) mod N formula to permute shingle index\n",
        "    # where a,b are random numbers, N total index size, and x is the index\n",
        "# We need to do L permutations - In other words we need to have L permutations (lists) of new indexes\n",
        "# Following function takes total index size N and L as arguments\n",
        "    # And returns L new lists of size N\n",
        "    \n",
        "def get_hash_functions(N,L):\n",
        "    hash_functions = []\n",
        "    \n",
        "    for itr in range(L):\n",
        "        a=randrange(1,400)\n",
        "        b=randrange(1,400)\n",
        "        \n",
        "        new_hash_function = []\n",
        "        for i in range(N):\n",
        "            new_hash_function.append((a * i + b) % N)\n",
        "        \n",
        "        hash_functions.append(new_hash_function)\n",
        "    return hash_functions\n",
        "        \n",
        "# test\n",
        "#hash_functions = get_hash_functions(len(shingles_set),1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxT3D4jMo-EC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOSXspETQwby"
      },
      "source": [
        "#### For L = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zX9juJNQeZu"
      },
      "source": [
        "### Generating Signature Matrix\n",
        "# For L = 50\n",
        "L = 50\n",
        "\n",
        "hash_functions = get_hash_functions(len(shingles_set), L)\n",
        "signature_matrix = np.full((L, len(dictionary)), np.inf)\n",
        "\n",
        "for k in range(0, L):\n",
        "  scrambled = hash_functions[k]\n",
        "  for i in range(0, len(shingles_set)):\n",
        "    current_index = scrambled[i]\n",
        "    shingle = shingles_list[i]\n",
        "    for j in range(0, len(dictionary)):\n",
        "      if shingle in dictionary[j]:\n",
        "        if current_index < signature_matrix[k][j]:\n",
        "          signature_matrix[k][j] = current_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3z0PTDuQePu"
      },
      "source": [
        "#signature_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0MeCly7QeNm"
      },
      "source": [
        "## Getting Jaccard Similarity with one of the original documents with all the sample documents\n",
        "similarity_count = collections.defaultdict(float)\n",
        "original = signature_matrix[:,58]\n",
        "for i in range(0, 57):\n",
        "  another = signature_matrix[:,i]\n",
        "  comparison = original == another\n",
        "  count = np.count_nonzero(comparison)\n",
        "  similarity_count[i] = (count/L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZguJtMaQeL8"
      },
      "source": [
        "#similarity_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TCHogx8QeKC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7565d54f-3476-4da0-b2d2-c494623f5f33"
      },
      "source": [
        "## Documetns having Jaccard Similarity greater than 20%\n",
        "answer = []\n",
        "print(\"Comparing candidates with \" + name_index[58])\n",
        "for key, value in similarity_count.items():\n",
        "  if value > 0.2:\n",
        "    string = str(similarity_count[key]) + \" similarity in \" + name_index[key]\n",
        "    answer.append(string)\n",
        "    #print(name_index[key] + \" Similarity \" + str(similarity_count[key]))\n",
        "answer.sort(reverse=True)\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing candidates with orig_taske.txt\n",
            "['0.6 similarity in g4pB_taske.txt', '0.5 similarity in g2pB_taske.txt', '0.32 similarity in g4pC_taske.txt', '0.22 similarity in g1pB_taske.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgt9CTdgRxnO"
      },
      "source": [
        "### For L = 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpoJZSJEQeHI"
      },
      "source": [
        "L = 100\n",
        "\n",
        "hash_functions = get_hash_functions(len(shingles_set), L)\n",
        "signature_matrix = np.full((L, len(dictionary)), np.inf)\n",
        "\n",
        "for k in range(0, L):\n",
        "  scrambled = hash_functions[k]\n",
        "  for i in range(0, len(shingles_set)):\n",
        "    current_index = scrambled[i]\n",
        "    shingle = shingles_list[i]\n",
        "    for j in range(0, len(dictionary)):\n",
        "      if shingle in dictionary[j]:\n",
        "        if current_index < signature_matrix[k][j]:\n",
        "          signature_matrix[k][j] = current_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIqnK6sAo-xv"
      },
      "source": [
        "#signature_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMkd-34Uo-0Z"
      },
      "source": [
        "similarity_count = collections.defaultdict(float)\n",
        "original = signature_matrix[:,59]\n",
        "for i in range(0, 57):\n",
        "  another = signature_matrix[:,i]\n",
        "  comparison = original == another\n",
        "  count = np.count_nonzero(comparison)\n",
        "  similarity_count[i] = (count/L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guxwpUCKo_Cz"
      },
      "source": [
        "#similarity_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU_ygh9Eo-_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6970f4f3-ce32-41d6-ee7f-2fb155b0cc70"
      },
      "source": [
        "## Documetns having Jaccard Similarity greater than 20%\n",
        "answer = []\n",
        "print(\"Comparing candidates with \" + name_index[58])\n",
        "for key, value in similarity_count.items():\n",
        "  if value > 0.2:\n",
        "    string = str(similarity_count[key]) + \" similarity in \" + name_index[key]\n",
        "    answer.append(string)\n",
        "    #print(name_index[key] + \" Similarity \" + str(similarity_count[key]))\n",
        "answer.sort(reverse=True)\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing candidates with orig_taske.txt\n",
            "['0.46 similarity in g4pE_taskb.txt', '0.34 similarity in g0pA_taskb.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhf98ZoNT_B-"
      },
      "source": [
        "### For L = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C83zCqRdo--f"
      },
      "source": [
        "L = 200\n",
        "\n",
        "hash_functions = get_hash_functions(len(shingles_set), L)\n",
        "signature_matrix = np.full((L, len(dictionary)), np.inf)\n",
        "\n",
        "for k in range(0, L):\n",
        "  scrambled = hash_functions[k]\n",
        "  for i in range(0, len(shingles_set)):\n",
        "    current_index = scrambled[i]\n",
        "    shingle = shingles_list[i]\n",
        "    for j in range(0, len(dictionary)):\n",
        "      if shingle in dictionary[j]:\n",
        "        if current_index < signature_matrix[k][j]:\n",
        "          signature_matrix[k][j] = current_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNhZx-m6o-7t"
      },
      "source": [
        "similarity_count = collections.defaultdict(float)\n",
        "original = signature_matrix[:,57]\n",
        "for i in range(0, 57):\n",
        "  another = signature_matrix[:,i]\n",
        "  comparison = original == another\n",
        "  count = np.count_nonzero(comparison)\n",
        "  similarity_count[i] = (count/L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70XdNJLso-48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "062ecbbb-5912-4fdf-e47d-b579fdc58767"
      },
      "source": [
        "## Documetns having Jaccard Similarity greater than 20%\n",
        "answer = []\n",
        "print(\"Comparing candidates with \" + name_index[58])\n",
        "for key, value in similarity_count.items():\n",
        "  if value > 0.2:\n",
        "    string = str(similarity_count[key]) + \" similarity in \" + name_index[key]\n",
        "    answer.append(string)\n",
        "    #print(name_index[key] + \" Similarity \" + str(similarity_count[key]))\n",
        "answer.sort(reverse=True)\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing candidates with orig_taskd.txt\n",
            "g3pA_taskd.txt Similarity 0.91\n",
            "g4pC_taskd.txt Similarity 0.685\n",
            "g4pB_taskd.txt Similarity 0.21\n",
            "g2pB_taskd.txt Similarity 0.43\n",
            "g0pC_taskd.txt Similarity 0.425\n",
            "g2pA_taskd.txt Similarity 0.285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkTY7Sgwo-Lz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf5Vv1nLUnQt"
      },
      "source": [
        "### L = 500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GLHiHh6Ump7"
      },
      "source": [
        "L = 500\n",
        "\n",
        "hash_functions = get_hash_functions(len(shingles_set), L)\n",
        "signature_matrix = np.full((L, len(dictionary)), np.inf)\n",
        "\n",
        "for k in range(0, L):\n",
        "  scrambled = hash_functions[k]\n",
        "  for i in range(0, len(shingles_set)):\n",
        "    current_index = scrambled[i]\n",
        "    shingle = shingles_list[i]\n",
        "    for j in range(0, len(dictionary)):\n",
        "      if shingle in dictionary[j]:\n",
        "        if current_index < signature_matrix[k][j]:\n",
        "          signature_matrix[k][j] = current_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IHubGs3o-JU"
      },
      "source": [
        "similarity_count = collections.defaultdict(float)\n",
        "original = signature_matrix[:,59]\n",
        "for i in range(0, 57):\n",
        "  another = signature_matrix[:,i]\n",
        "  comparison = original == another\n",
        "  count = np.count_nonzero(comparison)\n",
        "  similarity_count[i] = (count/L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4r99Um0o-BE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "9d527305-92a6-4850-d3da-c8c2e93f6deb"
      },
      "source": [
        "## Documetns having Jaccard Similarity greater than 20%\n",
        "answer = []\n",
        "print(\"Comparing candidates with \" + name_index[58])\n",
        "for key, value in similarity_count.items():\n",
        "  if value > 0.2:\n",
        "    string = str(similarity_count[key]) + \" similarity in \" + name_index[key]\n",
        "    answer.append(string)\n",
        "    #print(name_index[key] + \" Similarity \" + str(similarity_count[key]))\n",
        "answer.sort(reverse=True)\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing candidates with orig_taskb.txt\n",
            "g4pE_taskb.txt Similarity 0.352\n",
            "g0pA_taskb.txt Similarity 0.366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hG6D4lGJo9-T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPSiJm-3U29r"
      },
      "source": [
        "### L = 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_JrOQJYo97q"
      },
      "source": [
        "L = 1000\n",
        "\n",
        "hash_functions = get_hash_functions(len(shingles_set), L)\n",
        "signature_matrix = np.full((L, len(dictionary)), np.inf)\n",
        "\n",
        "for k in range(0, L):\n",
        "  scrambled = hash_functions[k]\n",
        "  for i in range(0, len(shingles_set)):\n",
        "    current_index = scrambled[i]\n",
        "    shingle = shingles_list[i]\n",
        "    for j in range(0, len(dictionary)):\n",
        "      if shingle in dictionary[j]:\n",
        "        if current_index < signature_matrix[k][j]:\n",
        "          signature_matrix[k][j] = current_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdtU_OoKU9Re"
      },
      "source": [
        "similarity_count = collections.defaultdict(float)\n",
        "original = signature_matrix[:,57]\n",
        "for i in range(0, 57):\n",
        "  another = signature_matrix[:,i]\n",
        "  comparison = original == another\n",
        "  count = np.count_nonzero(comparison)\n",
        "  similarity_count[i] = (count/L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CMG5g3kU9hg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "26c77442-5d8d-4c9a-ea08-31453fe82385"
      },
      "source": [
        "## Documetns having Jaccard Similarity greater than 20%\n",
        "answer = []\n",
        "print(\"Comparing candidates with \" + name_index[58])\n",
        "for key, value in similarity_count.items():\n",
        "  if value > 0.2:\n",
        "    string = str(similarity_count[key]) + \" similarity in \" + name_index[key]\n",
        "    answer.append(string)\n",
        "    #print(name_index[key] + \" Similarity \" + str(similarity_count[key]))\n",
        "answer.sort(reverse=True)\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comparing candidates with orig_taskd.txt\n",
            "g3pA_taskd.txt Similarity 0.923\n",
            "g4pC_taskd.txt Similarity 0.705\n",
            "g4pB_taskd.txt Similarity 0.229\n",
            "g2pB_taskd.txt Similarity 0.493\n",
            "g0pC_taskd.txt Similarity 0.333\n",
            "g2pA_taskd.txt Similarity 0.205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Ge6u9uU9k1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cldKHMv96ilO"
      },
      "source": [
        "### STEP - 3: LSH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4EeONg1iyxt"
      },
      "source": [
        "# r and B values t values\n",
        "r = 20\n",
        "B = 199\n",
        "t = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rIwiVYuiy0m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXx4WkJniy6u"
      },
      "source": [
        "from numpy import random\n",
        "\n",
        "x=random.randint(1000, size=(r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxC7i0R9qdd4"
      },
      "source": [
        "buckets = collections.defaultdict(set)\n",
        "\n",
        "index = 0\n",
        "temp_dict = collections.defaultdict(list)\n",
        "\n",
        "while index < 1000:\n",
        "  for doc_index in range(0, 57):\n",
        "     band = signature_matrix[index:index+r, doc_index]\n",
        "     bucket_id = np.sum(np.prod([band,x], axis=0)) % B\n",
        "     temp_dict[bucket_id].append(doc_index)\n",
        "\n",
        "  index += r\n",
        "  for key, value in temp_dict.items():\n",
        "    if len(value) > 1:\n",
        "      for i in value:\n",
        "        buckets[key].add(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTTg8iCOxMvl"
      },
      "source": [
        "index = 0\n",
        "candidate_docs = set()\n",
        "for doc_index in range(59, 60):\n",
        "  while index < 1000:\n",
        "    band = signature_matrix[index:index+r, doc_index]\n",
        "    bucket_id = np.sum(np.prod([band,x], axis=0)) % B\n",
        "    li = buckets[bucket_id]\n",
        "    candidate_docs.update(li)\n",
        "    index = index + r\n",
        "  index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FQZNC-8xMIs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86af7d5a-32d3-4503-bc7b-df456b937ab3"
      },
      "source": [
        "print(\"Total number of candidate documents: \" + str(len(candidate_docs)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of candidate documents: 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k2Ldq5vxMFt"
      },
      "source": [
        "#candidate_docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj_KEAr66ilh"
      },
      "source": [
        "Report all documents (file_names) below that have Jaccard similarity > t=0.20\n",
        "Sort the documents in decreasing order of the Jaccard similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKR9_p9Zsyfw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqsOUKWFdPTJ"
      },
      "source": [
        "candidates_list = list(candidate_docs)\n",
        "similarity_count = collections.defaultdict(float)\n",
        "original = signature_matrix[:,57]\n",
        "for i in candidates_list:\n",
        "  another = signature_matrix[:,i]\n",
        "  comparison = original == another\n",
        "  count = np.count_nonzero(comparison)\n",
        "  similarity_count[i] = (count/1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLp7g_1d38q-"
      },
      "source": [
        "#similarity_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC3ivIMemuhL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "7945bfde-471e-43cc-dedb-43cc5c856924"
      },
      "source": [
        "## Documetns having Jaccard Similarity greater than 20%\n",
        "answer = []\n",
        "print(\"Comparing candidates with \" + name_index[58])\n",
        "for key, value in similarity_count.items():\n",
        "  if value > 0.2:\n",
        "    string = str(similarity_count[key]) + \" similarity in \" + name_index[key]\n",
        "    answer.append(string)\n",
        "    #print(name_index[key] + \" Similarity \" + str(similarity_count[key]))\n",
        "answer.sort(reverse=True)\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comaparing candidates with orig_taskd.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0.923 similarity in document g3pA_taskd.txt',\n",
              " '0.705 similarity in document g4pC_taskd.txt',\n",
              " '0.229 similarity in document g4pB_taskd.txt',\n",
              " '0.493 similarity in document g2pB_taskd.txt',\n",
              " '0.333 similarity in document g0pC_taskd.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bZwfh536ilk"
      },
      "source": [
        "Report the list of false positives and false negatives below\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZibmWNuGvWaU"
      },
      "source": [
        "For L = 1000, b = 50, r = 20\n",
        "Candidate documents obtained from LSH are 57\n",
        "Hence, false positive = 51 and false negative = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjJouMqlsH_e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMwzk1Zx6ilp"
      },
      "source": [
        "# Experiment with different values of b,r,B, and t\n",
        "    # to reduce the number of false positives and false negatives\n",
        "    # Report all results in a table in a separate word document\n",
        "\n",
        "# r and B values t values\n",
        "r = 50\n",
        "B = 299\n",
        "t = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUjTcqHJwcH0"
      },
      "source": [
        "from numpy import random\n",
        "\n",
        "x=random.randint(1000, size=(r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N5HWHuawfxb"
      },
      "source": [
        "buckets = collections.defaultdict(set)\n",
        "\n",
        "index = 0\n",
        "temp_dict = collections.defaultdict(list)\n",
        "\n",
        "while index < 1000:\n",
        "  for doc_index in range(0, 57):\n",
        "     band = signature_matrix[index:index+r, doc_index]\n",
        "     bucket_id = np.sum(np.prod([band,x], axis=0)) % B\n",
        "     temp_dict[bucket_id].append(doc_index)\n",
        "\n",
        "  index += r\n",
        "  for key, value in temp_dict.items():\n",
        "    if len(value) > 1:\n",
        "      for i in value:\n",
        "        buckets[key].add(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGIGxHjcwmyU"
      },
      "source": [
        "index = 0\n",
        "candidate_docs = set()\n",
        "for doc_index in range(59, 60):\n",
        "  while index < 1000:\n",
        "    band = signature_matrix[index:index+r, doc_index]\n",
        "    bucket_id = np.sum(np.prod([band,x], axis=0)) % B\n",
        "    li = buckets[bucket_id]\n",
        "    candidate_docs.update(li)\n",
        "    index = index + r\n",
        "  index = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzSUqDFAwpb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "288c5b54-85ff-4da8-8198-2fc6d97c5994"
      },
      "source": [
        "print(\"Total number of candidate documents: \" + str(len(candidate_docs)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of candidate documents: 42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sPqDH84wtQy"
      },
      "source": [
        "candidates_list = list(candidate_docs)\n",
        "similarity_count = collections.defaultdict(float)\n",
        "original = signature_matrix[:,57]\n",
        "for i in candidates_list:\n",
        "  another = signature_matrix[:,i]\n",
        "  comparison = original == another\n",
        "  count = np.count_nonzero(comparison)\n",
        "  similarity_count[i] = (count/1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwQYgX05wzbj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "337bba10-fc0d-48b5-9efd-568b255bd7ee"
      },
      "source": [
        "## Documetns having Jaccard Similarity greater than 20%\n",
        "answer = []\n",
        "print(\"Comparing candidates with \" + name_index[58])\n",
        "for key, value in similarity_count.items():\n",
        "  if value > 0.2:\n",
        "    string = str(similarity_count[key]) + \" similarity in \" + name_index[key]\n",
        "    answer.append(string)\n",
        "    #print(name_index[key] + \" Similarity \" + str(similarity_count[key]))\n",
        "answer.sort(reverse=True)\n",
        "print(answer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Comaparing candidates with orig_taskd.txt\n",
            "g3pA_taskd.txt Similarity 0.923\n",
            "g4pC_taskd.txt Similarity 0.705\n",
            "g4pB_taskd.txt Similarity 0.229\n",
            "g2pB_taskd.txt Similarity 0.493\n",
            "g0pC_taskd.txt Similarity 0.333\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}